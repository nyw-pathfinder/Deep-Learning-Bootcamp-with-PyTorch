{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "name": "06-training.ipynb",
    "colab": {
      "name": "06-training.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMDcFHeqRcTu"
      },
      "source": [
        "# Table of Contents\n",
        "\n",
        "- [Training](#train)\n",
        "- [Exercises](#exercises)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uw8GrzfRcTx"
      },
      "source": [
        "# Housekeeping\n",
        "\n",
        "- Some references for today\n",
        "  - [Official pytorch tutorials](https://pytorch.org/tutorials/)\n",
        "  - [Pytorch tutorials by yunjey, from beginning to advanced](https://github.com/yunjey/pytorch-tutorial)\n",
        "  - [MIT Intro to Deep Learning](https://www.youtube.com/watch?v=njKP3FqW3Sk&list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&index=1) lecture video \n",
        "    (overview of machine learning and neural networks)\n",
        "  - [Machine Learning Basics](https://www.deeplearningbook.org/contents/ml.html) from the Deep Learning Book \n",
        "    (especially section 5.2 on Capacity, Overfitting and Underfitting)\n",
        "- Today's url \n",
        "  - https://git.io/ml2021-06\n",
        "- Email if you need help with any of this!\n",
        "\n",
        "# Some Preliminary Words on Training <a id=\"training\" />\n",
        "\n",
        "- In the last weeks, we learnt how to create neural networks in pytorch, and\n",
        "  about some of the loss functions and optimizers we are able to use\n",
        "- We saw its easy to take some data, throw a neural network at it and\n",
        "  get it to train\n",
        "- The hard part is developing a *good* model for the data\n",
        "- Neural networks are prone to failure modes we'll discuss today\n",
        "- Its important to understand these failure modes and build *robust*\n",
        "  networks\n",
        "- So, before moving onto the deep learning topics that we'll spend the\n",
        "  rest of the course on, lets stop and talk a bit about training\n",
        "\n",
        "# Generalization\n",
        "\n",
        "- The goal of building a model on known inputs is that we want the\n",
        "  model to *generalize* to unlabelled data\n",
        "- That is, the data should correctly classify data from outside the training set\n",
        "- If the model only works on datapoints in the training, its not much use\n",
        "  - Imagine your a medical expert training a network to detect cancer,\n",
        "    you build a cancer classifier which takes as inputs MRI scans. If\n",
        "    it works correctly on images its seen in the training set\n",
        "    (labelled by doctors based on patient outcomes), but randomly\n",
        "    assigns labels to other images, its not useful to you at all, and\n",
        "    could cost lives!\n",
        "- The goal of this lesson is to figure out how best to train models\n",
        "  that generalize\n",
        "\n",
        "# Undertraining and Overtraining\n",
        "\n",
        "- **Undertraining** is when a model isn't complex enough to be able to\n",
        "  find the trends in the data\n",
        "  - Imagine a regression task where the data follows a quadratic\n",
        "    curve, fitting a linear function won't be able to capture all the information\n",
        "- **Overtraining** is when a model is too complex and it begins fitting\n",
        "  *fluctuations* in the labelled datapoints\n",
        "  - We imagine theres some random errors in the data that can't be\n",
        "    modelled, when a model is overtrained, it takes these random\n",
        "    errors seriously and forms a model for them, which can't\n",
        "    generalize to unseen data\n",
        "\n",
        "As we increase the polynomial order of the fit function, we start to overtrain\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUVkpXccRcTy",
        "outputId": "bc4b2abf-ba63-4f68-cca6-c8f6b3feefbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        }
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "npoints = 50\n",
        "red = torch.stack((torch.randn(npoints), torch.randn(npoints)), axis=1)\n",
        "blue = torch.stack((torch.randn(npoints)+1.5, torch.randn(npoints)+1.5), axis=1)\n",
        "\n",
        "plt.scatter(red[:,0], red[:,1], c='r');plt.scatter(blue[:,0], blue[:,1], c='b')\n",
        "plt.show()\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "  def __init__(self, n):\n",
        "    super(Model, self).__init__()\n",
        "    self.n = n\n",
        "    self.fc1 = torch.nn.Linear(2,n)\n",
        "    self.fc2 = torch.nn.Linear(n,n)\n",
        "    self.fc3 = torch.nn.Linear(n,1)\n",
        "  def forward(self, x):\n",
        "    #x = torch.stack([x**i for i in range(self.n+1)], axis=1)\n",
        "    x = th.relu(self.fc1(x))\n",
        "    x = th.relu(self.fc2(x))\n",
        "    x = th.sigmoid(self.fc3(x))\n",
        "    return x\n",
        "\n",
        "xs = th.cat([red,blue])\n",
        "ys = th.cat([th.ones(len(red)), th.zeros(len(blue))])\n",
        "print(\"UNDERTRAINED?\")\n",
        "\n",
        "def showmodel(n):\n",
        " m = Model(n)\n",
        " lossf = torch.nn.BCELoss()\n",
        " optim = torch.optim.AdamW(m.parameters(),lr=0.01)\n",
        " for _ in range(2500):\n",
        "   optim.zero_grad()\n",
        "   fs = m(xs)\n",
        "   loss = lossf(fs.view(-1), ys)\n",
        "   loss.backward()\n",
        "   optim.step()\n",
        " x1,x2=np.meshgrid(np.linspace(-4,4), np.linspace(-4,4))\n",
        " col = m(th.tensor(np.dstack([x1,x2])).float())\n",
        " plt.imshow(col.detach().numpy(),origin='lower',extent=(-4,4,-4,4), cmap='bwr')\n",
        " plt.scatter(red[:,0], red[:,1], c='r',edgecolor='k');plt.scatter(blue[:,0], blue[:,1], c='b', edgecolor='k')\n",
        " plt.show()\n",
        "showmodel(2)\n",
        "showmodel(8)\n",
        "showmodel(32)\n",
        "showmodel(256)\n",
        "print(\"OVERTRAINED?\")\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1f536c2e3784>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"UNDERTRAINED?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'th' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzgASgIWRcT1"
      },
      "source": [
        "# Model Capacity\n",
        "- A model's *capacity* is its ability to fit a wide variety of functions\n",
        "- Models with low capacity might struggle to fit the training set,\n",
        "  while those with high capacity can memorize parts of the training\n",
        "  set that don't generalize, in the extreme just memorizes the entire dataset\n",
        "- Capacity can be controlled in different ways depending on the model\n",
        "- E.g. last week we considered linear regression, we can increase the\n",
        "  capacity by allow higher order terms as new features\n",
        "  - Linear regression models the relationship of $y$ and $x$ by assuming $y = ax + b$\n",
        "  - If we introduce $x^2$ as a feature, we can additionally model\n",
        "    quadratic relationships, $y=ax^2+bx+c$\n",
        "  - The more terms we allow, the more features we can model, but the\n",
        "    greater the chance we memorize datapoints rather than the trends\n",
        "- For our basic neural networks, capacity increases with increasing\n",
        "  number of nodes in the hidden layer, and with increasing number of\n",
        "  layers\n",
        "\n",
        "# The Bias-Variance Tradeoff\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiVmuFufRcT3"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(\"bias-variance.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_h5ufL1RcT3"
      },
      "source": [
        "- *Bias*: the difference between our model prediction and the datapoints\n",
        "  - A high *bias* model has large differences between the datapoints\n",
        "  - A model which doesn't have enough parameters *underfits* the data\n",
        "- *Variance, a measure of the fluctuations of the data or model, high\n",
        "  variance models are typically fitting the intrinsic noise of the data\n",
        "  - A high variance model implies small changes in the input cause large changes in the output\n",
        "  - A high variance model with too many parameters *overfits* the data\n",
        "- The *bias-variance trade off* is a theorem which tells us that you\n",
        "  trade off model bias for variance and vice-versa, in practice we try\n",
        "  to find a happy medium between the two\n",
        "  - (Formally, the bias variance tradeoff concerns the behaivour of\n",
        "    statistical estimators, in practice in ML, we have a fuzzy idea as\n",
        "    described above, see the Deep Learning Book for the math)\n",
        "\n",
        "# Testing and Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF5orXBORcT4"
      },
      "source": [
        "plt.plot(training_loss, label='train')\n",
        "plt.plot(testing_loss, label='test')\n",
        "plt.legend(loc='upper right'); plt.xlabel('epoch'); plt.ylabel('loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNU6CIyNRcT4"
      },
      "source": [
        "- When <font color=blue>training</font> a model, in order to check for overtraining, we\n",
        "  generally set aside some portion of the (labelled) data as a <font color=orange>test set</font>\n",
        "  - The <font color=orange>test set</font> is *never* used in the <font color=blue>training</font> stage\n",
        "  - The exactly split depends on how much data you have, 20% is a good\n",
        "    rough number if you really have no idea\n",
        "- We periodically check the model with the <font color=orange>test set</font>, and check to see\n",
        "  if the average loss of the <font color=blue>training</font>\n",
        "- The <font color=blue>training</font> average should follow the <font color=orange>test set</font> average, they will\n",
        "  diverge when the model starts overtraining\n",
        "\n",
        "# k-fold Cross-Validation\n",
        "- For models which can be trivially trained in a short amount of time,\n",
        "  you can also do more sophisticated checks such as k-fold\n",
        "  cross-validation\n",
        "  - Split the data into k equal sized subset, train k times, holding a\n",
        "    different subset each time, where each time training with k-1 of\n",
        "    the subsets, and using the the held out subset as the training sample\n",
        "  - You can use the properties of the k predictions as an estimator of\n",
        "    the bias and variance of the selected model (typically, you would\n",
        "    be using this to tune hyperparameters or something similar)\n",
        "- High bias models will have uniformly bad results across all test cases\n",
        "  - Always gets it wrong, but wrong in the same way across the test sets\n",
        "- High variance models will have highly divergent results between the\n",
        "  test sets\n",
        "  - Gets it wrong in unique ways across the test sets, since the\n",
        "    different sets have different exact fluctuations\n",
        "- A typical training regime could be:\n",
        "  - split into test and training, \n",
        "  - do k-fold cross-validation to find a good set of hyperparameters, \n",
        "  - train on the full training set, then \n",
        "  - check performance on the test set\n",
        "\n",
        "# Early Stopping\n",
        "\n",
        "- In deep learning, a single model can contain millions of parameters\n",
        "  and training can take days or weeks\n",
        "- In this case, sophisticated techniques aren't viable and instead, as\n",
        "  well as saving information on the loss, you also save the model weights\n",
        "- Then you check the testing-training loss as you go, and *choose* the\n",
        "  model parameters when the test and training curves begin diverging\n",
        "- This is early stopping, you stop training and take the model at a\n",
        "  point where it hasn't overtrained, rather than fully training the\n",
        "  model\n",
        "- In the case illustrated here, my solution to today's exercise,\n",
        "  the model starts overtraining after 4 or 5 epochs, so we'd use the\n",
        "  5-epoch model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qRcd9vBRcT5"
      },
      "source": [
        "# Training, Testing and Validation\n",
        "\n",
        "- One further complication, if you're also doing an extensive\n",
        "  *hyperparameter* search, you may also want to set aside a\n",
        "  `validation` set, as well as a testing and training set\n",
        "  - *hyperparameters* are parameters used in training the model, which\n",
        "    could be the loss rate of the SGD, the number of nodes, or even\n",
        "    switching in and out different types of models\n",
        "- In an extensive hyperparameter search, you could also be implicitly\n",
        "  tuning to the testing set, since you're using the testing results as a\n",
        "  goodness-of-model for potentially thousands of models\n",
        "  - Thus, the model you choose might just happen to be a good fit to\n",
        "    the test set because you're comparing lots of models via the test\n",
        "    set, not because it actually generalizes well\n",
        "- Thus, the validation set is set aside and not used in the testing\n",
        "  stage, but only after you've selected your final model\n",
        "  - A truly generalizable model should also have good properties on\n",
        "    the validation set, if not, you may have fit the hyperparameters\n",
        "    to the test, rather than found a generalizable model\n",
        "- When you're searching for a good model for your problem and have\n",
        "  lots of data, also keep aside a validation dataset for a final\n",
        "  validation of your selected model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47_SDJ3-RcT6"
      },
      "source": [
        "# Testing and Training in PyTorch\n",
        "\n",
        "- In pytorch, you should set your network into training mode when\n",
        "  training, and evaluation mode when testing (or running in production)\n",
        "- The differences will become important and make more sense when we\n",
        "  start talking about *regularization* later on in the course\n",
        "  - For now, just get use to the fact that you should set the network\n",
        "    into training mode when training, and eval mode otherwise\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ifKnu5ARcT6"
      },
      "source": [
        "net.train() # set into training mode\n",
        "# do training\n",
        "net.eval() # set into evaluation mode\n",
        "# do testing, or production"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkHGt1VkRcT6"
      },
      "source": [
        "# A Typical Training Loop in PyTorch\n",
        "\n",
        "- Here is a basic training loop with a testing phase at the end of each epoch\n",
        "- Assume `net` is our neural net (or other model), `data_training` is\n",
        "  a list of `(input, label)` pairs pre-split into minibatches and\n",
        "  `data_testing` is a tuple of the test inputs and corresponding labels,\n",
        "  `optimizer` is the optimizer, `criterion` is the loss function,\n",
        "  `device` is a cuda or cpu device\n",
        "- We keep track of the running loss to compute the average over the\n",
        "  epoch and compare with the test set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKTODAr2RcT7"
      },
      "source": [
        "inputs_testing, labels_testing = data_testing[0].to(device), data_testing[1].to(device)\n",
        "for epoch in range(num_epochs):\n",
        "  net.train()\n",
        "  running_loss, running_correct, running_n = 0.0, 0.0, 0.0\n",
        "  for inputs, labels in data_batches:\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    running_loss += loss.item() * inputs.size(0) # loss is the avg. for the batch\n",
        "    # max returns a tuple of tensors: (highest value, index of highest value)\n",
        "    running_correct += torch.sum(torch.max(outputs,1)[1] == labels.data)\n",
        "    running_n += inputs.size(0)\n",
        "    optimizer.step()\n",
        "  print(\"Train loss: {:.3f} acc: {:.3f}\".format(running_loss / running_n, running_correct / running_n))\n",
        "  net.eval()\n",
        "  outputs = net(inputs_testing)\n",
        "  loss = criterion(outputs, labels_testing)\n",
        "  print(\"Test  loss: {:.3f} acc: {:.3f}\".format(loss / inputs_testing.size(0))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWR2oHtoRcT7"
      },
      "source": [
        "# Early Stopping in PyTorch, Saving/Loading Models\n",
        "\n",
        "- In pytorch, saving a model implies saving the model weights\n",
        "  - To load the model, you create the model as normal, and then load the saved weights back in\n",
        "- To save the model weights into a file, you can use `torch.save`, which you need to pass the \"state_dict\" and a filename"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIusTeuIRcT8"
      },
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DhsMlfvRcT9"
      },
      "source": [
        "- To load the weights back in, create the model, then call `load_state_dict` with the result of `torch.load`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt6yqbSaRcT9"
      },
      "source": [
        "model = Net() # Say we have a network called `Net`\n",
        "model.load_state_dict(torch.load('model_weights.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmhNz4XBRcT-"
      },
      "source": [
        "- To implement early stopping, we can keep track of the testing loss, and save the model whenever we have the lowest currently seen loss\n",
        "- In this way, what gets saved out at the end of the run is the model state with the lowest seen training loss over the whole training\n",
        "\n",
        "One final ancilliary issue: you can build up straightfoward networks with `Sequential`, which will pass the data through one layer at a time. There are `th.nn.ReLU` and equivalent layers for the activation functions. This is limited if you want to make some of the more interesting networks we will see in the future, but in the complete example below, you can see its even useful for defining subnetworks inside a full network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxEuO3kzRcT-"
      },
      "source": [
        "# A Fisher Iris network 4 inputs -> 32 hidden layer with relu activation -> 3 outputs\n",
        "net = th.nn.Sequential(th.nn.Linear(4,32), th.nn.ReLU(), th.nn.Linear(32, 3))\n",
        "net(th.tensor([1,2,3,4.]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8YbDDG8RcT_"
      },
      "source": [
        "Here is a complete example, using the FasionMNIST dataset  with a simple CNN. As always, when running, change the data directory to somewhere you have access to. Its a nice example of overtraining. Here, instead of running for a fixed number of epochs, we run until we haven't saved the network out for 20 epochs. This is another hyperparameter sometimes called \"patience\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKedKhVyRcT_"
      },
      "source": [
        "device = 'cuda'\n",
        "import torch as th\n",
        "import torchvision as tv\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "trans = tv.transforms.ToTensor()\n",
        "train = th.utils.data.DataLoader(tv.datasets.FashionMNIST('/data/torchvision', train=True, download=True, transform=trans), batch_size=256)\n",
        "test = th.utils.data.DataLoader(tv.datasets.FashionMNIST('/data/torchvision', train=False, download=True, transform=trans), batch_size=256)\n",
        "\n",
        "class FNet(th.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # pack the conv2d+relu into a single structure\n",
        "        self.c1 = th.nn.Sequential(th.nn.Conv2d(1,8,7), th.nn.ReLU())\n",
        "        self.c2 = th.nn.Sequential(th.nn.Conv2d(8,16,5), th.nn.ReLU())\n",
        "        self.c3 = th.nn.Sequential(th.nn.Conv2d(16,32,3), th.nn.ReLU())\n",
        "        self.fc = th.nn.Linear(32*16*16,10)\n",
        "    def forward(self, x):\n",
        "        x = self.c1(x) # conv2d + relu, 22x22\n",
        "        x = self.c2(x) # 18x18\n",
        "        x = self.c3(x) # 16x16\n",
        "        x = x.view(-1, 32*16*16)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "net = FNet().to(device)\n",
        "opt = th.optim.Adam(net.parameters())\n",
        "l = th.nn.CrossEntropyLoss()\n",
        "per_epoch = defaultdict(lambda:[])\n",
        "last_save = 0\n",
        "e = 0\n",
        "while last_save < 20:\n",
        "    per_batch = defaultdict(lambda:[])\n",
        "    for images, labels in train:\n",
        "        opt.zero_grad()\n",
        "        outputs = net(images.to(device))\n",
        "        loss = l(outputs, labels.to(device))\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        per_batch[\"loss\"].append(loss.item()*images.size(0))\n",
        "        per_batch[\"corr\"].append(sum(th.max(outputs,1)[1].cpu()==labels))\n",
        "        per_batch[\"n\"].append(images.size(0))\n",
        "    per_epoch[\"loss\"].append(sum(per_batch[\"loss\"])/sum(per_batch[\"n\"]))\n",
        "    per_epoch[\"acc\"].append(sum(per_batch[\"corr\"])/sum(per_batch[\"n\"]))\n",
        "    for images, labels in test:\n",
        "        outputs = net(images.to(device))\n",
        "        loss = l(outputs, labels.to(device))\n",
        "        per_batch[\"tloss\"].append(loss.item()*images.size(0))\n",
        "        per_batch[\"tcorr\"].append(sum(th.max(outputs,1)[1].cpu()==labels))\n",
        "        per_batch[\"tn\"].append(images.size(0))\n",
        "    per_epoch[\"tloss\"].append(sum(per_batch[\"tloss\"])/sum(per_batch[\"tn\"]))\n",
        "    per_epoch[\"tacc\"].append(sum(per_batch[\"tcorr\"])/sum(per_batch[\"tn\"]))\n",
        "    print(f'epoch {e:03d} : train loss {per_epoch[\"loss\"][-1]:.3f} acc {per_epoch[\"acc\"][-1]:.3f} test loss {per_epoch[\"tloss\"][-1]:.3f} acc {per_epoch[\"tacc\"][-1]:.3f}')\n",
        "    # early stopping: if we are at the best epoch (= epoch with lowest loss), save the weights\n",
        "    last_save += 1; e += 1\n",
        "    if per_epoch[\"tloss\"][-1] == min(per_epoch[\"tloss\"]):\n",
        "        print(\"  saving network\")\n",
        "        th.save(net.state_dict(), 'fnet_weights.pt')\n",
        "        last_save = 0\n",
        "print(\"done training.\")\n",
        "# reload the best weights\n",
        "net.load_state_dict(th.load('fnet_weights.pt'))\n",
        "# Make plots of the training/testing losses\n",
        "plt.plot(per_epoch[\"loss\"], label=\"train\")\n",
        "plt.plot(per_epoch[\"tloss\"], label=\"test\")\n",
        "plt.legend(loc=\"upper right\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNytZ60oRcT_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnntpi_TRcT_"
      },
      "source": [
        "# Exercises <a id=\"exercises\" />\n",
        "\n",
        "- The exercises will introduce the CIFAR100 dataset, for which, as usual, we will\n",
        "  use the `torchvision` package to download and set up a `DataLoader`,\n",
        "  another helper feature that torch provides to help us process by\n",
        "  mini-batches.\n",
        "\n",
        "Today, lets introduce a more difficult. The goal of cifar100 is to take 32x32 color images of handwritten\n",
        "digits and classify each image into one of 100 categories.\n",
        "\n",
        "https://www.cs.toronto.edu/~kriz/cifar.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgPD1f9-RcUA"
      },
      "source": [
        "import torch as th\n",
        "import torchvision as tv\n",
        "trans = tv.transforms.ToTensor()\n",
        "train = tv.datasets.CIFAR100('/data/torchvision', train=True, download=True, transform=trans)\n",
        "test = tv.datasets.CIFAR100('/data/torchvision', train=False, download=True, transform=trans)\n",
        "print(train, \"\\n\", test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY8BH54DRcUA"
      },
      "source": [
        "The dataset can be iterated over and will return one image every\n",
        "iteration. In the following cell, change the cell so that it displays\n",
        "the first five images of the dataset, and prints out the corresponding\n",
        "truth labels. You can use, for example, `matplotlib.pyplot.imshow`to\n",
        "display the images. The data is 3x32x32, but `imshow` expects the color channels to come *last*, so you will need to shuffle the axes in order to do this. Check the pytorch documentation on `permute` to do this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB9pDLp8RcUA"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "for image, label in train:\n",
        "  print(image.shape,'\\n', label)\n",
        "  image2 = image.permute(1, 2, 0)  # [32, 32, 3]\n",
        "  plt.imshow(image2)\n",
        "  plt.show()  \n",
        "  break\n",
        "\n",
        "# Exercise: Update cell to display the images\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4arbVhtRcUB"
      },
      "source": [
        "The CIFAR100 dataset is big, with 60,000 images, 50k training and 10k testing. Therefore, we will\n",
        "process by mini-batches, rather than updating a full gradient descent\n",
        "once every time through the dataset. In order to create mini-batches,\n",
        "we could of course collect the images together ourselves, but lets\n",
        "instead use a `DataLoader`. We can pass the dataset in, and tell how\n",
        "we want to set up the mini-batches. The dataset we downloaded is the\n",
        "correct format to simply pass into the DataLoader, but we will see\n",
        "later that we can also write our own, if we have specialized data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4EXgg4QRcUB",
        "outputId": "9939f14f-5760-4b18-fb49-4e0db1853da0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch as th\n",
        "import torchvision as tv\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "trans = tv.transforms.ToTensor()\n",
        "train = tv.datasets.CIFAR100('/data/torchvision', train=True, download=True, transform=trans)\n",
        "test = tv.datasets.CIFAR100('/data/torchvision', train=False, download=True, transform=trans)\n",
        "print(train, \"\\n\", test)\n",
        "\n",
        "trainloader = th.utils.data.DataLoader(train, batch_size=64)\n",
        "testloader = th.utils.data.DataLoader(test, batch_size=64)\n",
        "# example of how this works, we get a tensor filled with one batch,\n",
        "# and the corresponding labels\n",
        "for images, labels in trainloader:\n",
        "  print(images.shape, labels.shape)\n",
        "  break\n",
        "\n",
        "#다시시작하기 및 모두실행이 필요하다. 종종 GPU로 바꿀때. "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Dataset CIFAR100\n",
            "    Number of datapoints: 50000\n",
            "    Root location: /data/torchvision\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor() \n",
            " Dataset CIFAR100\n",
            "    Number of datapoints: 10000\n",
            "    Root location: /data/torchvision\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "torch.Size([64, 3, 32, 32]) torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trLeYW8_RcUB"
      },
      "source": [
        "Now, we're in a position to set up the network. Write a basic\n",
        "convolutional neural network which will train on the CIFAR100 using\n",
        "`torch.nn.Module`. For now, you can keep it simple, with a few convolution layers followed by a fully connected linear layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WxmKWJ7RcUB"
      },
      "source": [
        "device = 'cuda'\n",
        "\n",
        "class Net(th.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = th.nn.Conv2d(3,6,5,1,padding=1) #색깔있는 이미지는 인풋 채널이 3개\n",
        "    self.conv2 = th.nn.Conv2d(6,16,5,1,padding=0) \n",
        "\n",
        "    self.fc1 = th.nn.Linear(400,120) #인풋 잘 찾가. \n",
        "    self.fc2 = th.nn.Linear(120,84)\n",
        "    self.fc3 = th.nn.Linear(84,100)\n",
        "\n",
        "  def forward(self, x):\n",
        "    #x = x.reshape(x.shape[0],-1)\n",
        "    x1 = th.tanh(self.conv1(x))\n",
        "    x1 = th.nn.AvgPool2d(kernel_size=2)(x1)\n",
        "    x2 = th.tanh(self.conv2(x1))\n",
        "    x2 = th.nn.AvgPool2d(kernel_size=2)(x2)\n",
        "    x2 = x2.reshape(x2.shape[0],-1)\n",
        "    # print(x2.shape)\n",
        "    x3 = self.fc1(x2)\n",
        "    x4 = self.fc2(x3)\n",
        "    x = self.fc3(x4)\n",
        "    return x\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUfYA8yvRcUB"
      },
      "source": [
        "Now that we have a network, we should train it! Create a training loop\n",
        "and train the network. You'll have to think what loss to use and\n",
        "choose an optimizer. Keep track of the average loss for training and\n",
        "testing of each epoch. Remember to use the GPU! Don't be too worried about getting high accuracy for the moment, just much better than chance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvYVjpsCRcUB",
        "outputId": "073e8796-a932-4f32-e0b3-db3854eb4cb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "net = Net().to(device)\n",
        "opt = th.optim.Adam(net.parameters())\n",
        "l = th.nn.CrossEntropyLoss()\n",
        "per_epoch = defaultdict(lambda:[])\n",
        "last_save = 0\n",
        "e = 0\n",
        "\n",
        "while last_save < 20:\n",
        "    per_batch = defaultdict(lambda:[])\n",
        "    i = 0\n",
        "    for images, labels in trainloader :\n",
        "      if i == 5\n",
        "      ; bre\n",
        "        opt.zero_grad()\n",
        "        outputs = net(images.to(device))\n",
        "        loss = l(outputs, labels.to(device))\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        per_batch[\"loss\"].append(loss.item()*images.size(0))\n",
        "        per_batch[\"corr\"].append(sum(th.max(outputs,1)[1].cpu()==labels))\n",
        "        per_batch[\"n\"].append(images.size(0))\n",
        "    per_epoch[\"loss\"].append(sum(per_batch[\"loss\"])/sum(per_batch[\"n\"]))\n",
        "    per_epoch[\"acc\"].append(sum(per_batch[\"corr\"])/sum(per_batch[\"n\"]))\n",
        "    for images, labels in testloader :\n",
        "        outputs = net(images.to(device))\n",
        "        loss = l(outputs, labels.to(device))\n",
        "        per_batch[\"tloss\"].append(loss.item()*images.size(0))\n",
        "        per_batch[\"tcorr\"].append(sum(th.max(outputs,1)[1].cpu()==labels))\n",
        "        per_batch[\"tn\"].append(images.size(0))\n",
        "    per_epoch[\"tloss\"].append(sum(per_batch[\"tloss\"])/sum(per_batch[\"tn\"]))\n",
        "    per_epoch[\"tacc\"].append(sum(per_batch[\"tcorr\"])/sum(per_batch[\"tn\"]))\n",
        "    print(f'epoch {e:03d} : train loss {per_epoch[\"loss\"][-1]:.3f} acc {per_epoch[\"acc\"][-1]:.3f} test loss {per_epoch[\"tloss\"][-1]:.3f} acc {per_epoch[\"tacc\"][-1]:.3f}')\n",
        "    # early stopping: if we are at the best epoch (= epoch with lowest loss), save the weights\n",
        "    last_save += 1; e += 1\n",
        "    if per_epoch[\"tloss\"][-1] == min(per_epoch[\"tloss\"]):\n",
        "        print(\"  saving network\")\n",
        "        th.save(net.state_dict(), 'fnet_weights.pt')\n",
        "        last_save = 0\n",
        "print(\"done training.\")\n",
        "# reload the best weights\n",
        "net.load_state_dict(th.load('fnet_weights.pt'))\n",
        "# Make plots of the training/testing losses\n",
        "plt.plot(per_epoch[\"loss\"], label=\"train\")\n",
        "plt.plot(per_epoch[\"tloss\"], label=\"test\")\n",
        "plt.legend(loc=\"upper right\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 000 : train loss 4.007 acc 0.094 test loss 3.779 acc 0.133\n",
            "  saving network\n",
            "epoch 001 : train loss 3.708 acc 0.150 test loss 3.651 acc 0.155\n",
            "  saving network\n",
            "epoch 002 : train loss 3.602 acc 0.169 test loss 3.583 acc 0.171\n",
            "  saving network\n",
            "epoch 003 : train loss 3.534 acc 0.182 test loss 3.546 acc 0.177\n",
            "  saving network\n",
            "epoch 004 : train loss 3.487 acc 0.190 test loss 3.514 acc 0.184\n",
            "  saving network\n",
            "epoch 005 : train loss 3.443 acc 0.197 test loss 3.477 acc 0.191\n",
            "  saving network\n",
            "epoch 006 : train loss 3.397 acc 0.205 test loss 3.437 acc 0.197\n",
            "  saving network\n",
            "epoch 007 : train loss 3.353 acc 0.214 test loss 3.400 acc 0.204\n",
            "  saving network\n",
            "epoch 008 : train loss 3.309 acc 0.220 test loss 3.372 acc 0.207\n",
            "  saving network\n",
            "epoch 009 : train loss 3.268 acc 0.226 test loss 3.348 acc 0.211\n",
            "  saving network\n",
            "epoch 010 : train loss 3.227 acc 0.235 test loss 3.320 acc 0.216\n",
            "  saving network\n",
            "epoch 011 : train loss 3.182 acc 0.242 test loss 3.285 acc 0.227\n",
            "  saving network\n",
            "epoch 012 : train loss 3.138 acc 0.251 test loss 3.253 acc 0.231\n",
            "  saving network\n",
            "epoch 013 : train loss 3.103 acc 0.257 test loss 3.231 acc 0.233\n",
            "  saving network\n",
            "epoch 014 : train loss 3.073 acc 0.263 test loss 3.212 acc 0.237\n",
            "  saving network\n",
            "epoch 015 : train loss 3.047 acc 0.268 test loss 3.195 acc 0.241\n",
            "  saving network\n",
            "epoch 016 : train loss 3.023 acc 0.273 test loss 3.179 acc 0.243\n",
            "  saving network\n",
            "epoch 017 : train loss 3.001 acc 0.277 test loss 3.165 acc 0.247\n",
            "  saving network\n",
            "epoch 018 : train loss 2.982 acc 0.281 test loss 3.154 acc 0.250\n",
            "  saving network\n",
            "epoch 019 : train loss 2.964 acc 0.285 test loss 3.144 acc 0.252\n",
            "  saving network\n",
            "epoch 020 : train loss 2.948 acc 0.287 test loss 3.135 acc 0.253\n",
            "  saving network\n",
            "epoch 021 : train loss 2.932 acc 0.290 test loss 3.126 acc 0.255\n",
            "  saving network\n",
            "epoch 022 : train loss 2.918 acc 0.294 test loss 3.119 acc 0.257\n",
            "  saving network\n",
            "epoch 023 : train loss 2.904 acc 0.297 test loss 3.112 acc 0.258\n",
            "  saving network\n",
            "epoch 024 : train loss 2.890 acc 0.299 test loss 3.106 acc 0.260\n",
            "  saving network\n",
            "epoch 025 : train loss 2.878 acc 0.302 test loss 3.100 acc 0.261\n",
            "  saving network\n",
            "epoch 026 : train loss 2.865 acc 0.304 test loss 3.094 acc 0.263\n",
            "  saving network\n",
            "epoch 027 : train loss 2.853 acc 0.306 test loss 3.089 acc 0.264\n",
            "  saving network\n",
            "epoch 028 : train loss 2.842 acc 0.309 test loss 3.084 acc 0.267\n",
            "  saving network\n",
            "epoch 029 : train loss 2.830 acc 0.311 test loss 3.080 acc 0.266\n",
            "  saving network\n",
            "epoch 030 : train loss 2.819 acc 0.313 test loss 3.075 acc 0.267\n",
            "  saving network\n",
            "epoch 031 : train loss 2.809 acc 0.315 test loss 3.071 acc 0.268\n",
            "  saving network\n",
            "epoch 032 : train loss 2.798 acc 0.317 test loss 3.068 acc 0.268\n",
            "  saving network\n",
            "epoch 033 : train loss 2.788 acc 0.319 test loss 3.064 acc 0.269\n",
            "  saving network\n",
            "epoch 034 : train loss 2.778 acc 0.321 test loss 3.061 acc 0.269\n",
            "  saving network\n",
            "epoch 035 : train loss 2.768 acc 0.323 test loss 3.057 acc 0.269\n",
            "  saving network\n",
            "epoch 036 : train loss 2.759 acc 0.325 test loss 3.054 acc 0.270\n",
            "  saving network\n",
            "epoch 037 : train loss 2.749 acc 0.327 test loss 3.051 acc 0.270\n",
            "  saving network\n",
            "epoch 038 : train loss 2.740 acc 0.328 test loss 3.047 acc 0.271\n",
            "  saving network\n",
            "epoch 039 : train loss 2.732 acc 0.330 test loss 3.044 acc 0.272\n",
            "  saving network\n",
            "epoch 040 : train loss 2.723 acc 0.331 test loss 3.040 acc 0.273\n",
            "  saving network\n",
            "epoch 041 : train loss 2.715 acc 0.333 test loss 3.037 acc 0.273\n",
            "  saving network\n",
            "epoch 042 : train loss 2.706 acc 0.335 test loss 3.033 acc 0.274\n",
            "  saving network\n",
            "epoch 043 : train loss 2.698 acc 0.336 test loss 3.029 acc 0.275\n",
            "  saving network\n",
            "epoch 044 : train loss 2.690 acc 0.338 test loss 3.025 acc 0.275\n",
            "  saving network\n",
            "epoch 045 : train loss 2.683 acc 0.340 test loss 3.022 acc 0.276\n",
            "  saving network\n",
            "epoch 046 : train loss 2.675 acc 0.341 test loss 3.018 acc 0.278\n",
            "  saving network\n",
            "epoch 047 : train loss 2.667 acc 0.343 test loss 3.015 acc 0.278\n",
            "  saving network\n",
            "epoch 048 : train loss 2.660 acc 0.344 test loss 3.012 acc 0.280\n",
            "  saving network\n",
            "epoch 049 : train loss 2.653 acc 0.345 test loss 3.009 acc 0.280\n",
            "  saving network\n",
            "epoch 050 : train loss 2.646 acc 0.347 test loss 3.006 acc 0.280\n",
            "  saving network\n",
            "epoch 051 : train loss 2.639 acc 0.348 test loss 3.003 acc 0.281\n",
            "  saving network\n",
            "epoch 052 : train loss 2.633 acc 0.350 test loss 3.001 acc 0.281\n",
            "  saving network\n",
            "epoch 053 : train loss 2.626 acc 0.351 test loss 2.999 acc 0.283\n",
            "  saving network\n",
            "epoch 054 : train loss 2.620 acc 0.352 test loss 2.996 acc 0.283\n",
            "  saving network\n",
            "epoch 055 : train loss 2.614 acc 0.353 test loss 2.994 acc 0.284\n",
            "  saving network\n",
            "epoch 056 : train loss 2.608 acc 0.354 test loss 2.992 acc 0.286\n",
            "  saving network\n",
            "epoch 057 : train loss 2.603 acc 0.356 test loss 2.990 acc 0.285\n",
            "  saving network\n",
            "epoch 058 : train loss 2.597 acc 0.357 test loss 2.989 acc 0.285\n",
            "  saving network\n",
            "epoch 059 : train loss 2.592 acc 0.358 test loss 2.987 acc 0.286\n",
            "  saving network\n",
            "epoch 060 : train loss 2.587 acc 0.359 test loss 2.986 acc 0.286\n",
            "  saving network\n",
            "epoch 061 : train loss 2.582 acc 0.360 test loss 2.984 acc 0.287\n",
            "  saving network\n",
            "epoch 062 : train loss 2.577 acc 0.360 test loss 2.983 acc 0.287\n",
            "  saving network\n",
            "epoch 063 : train loss 2.572 acc 0.361 test loss 2.981 acc 0.286\n",
            "  saving network\n",
            "epoch 064 : train loss 2.567 acc 0.361 test loss 2.980 acc 0.287\n",
            "  saving network\n",
            "epoch 065 : train loss 2.563 acc 0.362 test loss 2.979 acc 0.287\n",
            "  saving network\n",
            "epoch 066 : train loss 2.558 acc 0.363 test loss 2.978 acc 0.288\n",
            "  saving network\n",
            "epoch 067 : train loss 2.554 acc 0.364 test loss 2.977 acc 0.288\n",
            "  saving network\n",
            "epoch 068 : train loss 2.550 acc 0.365 test loss 2.976 acc 0.289\n",
            "  saving network\n",
            "epoch 069 : train loss 2.546 acc 0.366 test loss 2.976 acc 0.289\n",
            "  saving network\n",
            "epoch 070 : train loss 2.542 acc 0.367 test loss 2.975 acc 0.288\n",
            "  saving network\n",
            "epoch 071 : train loss 2.538 acc 0.367 test loss 2.974 acc 0.289\n",
            "  saving network\n",
            "epoch 072 : train loss 2.534 acc 0.368 test loss 2.974 acc 0.289\n",
            "  saving network\n",
            "epoch 073 : train loss 2.530 acc 0.369 test loss 2.973 acc 0.290\n",
            "  saving network\n",
            "epoch 074 : train loss 2.527 acc 0.370 test loss 2.973 acc 0.290\n",
            "  saving network\n",
            "epoch 075 : train loss 2.523 acc 0.370 test loss 2.972 acc 0.291\n",
            "  saving network\n",
            "epoch 076 : train loss 2.519 acc 0.372 test loss 2.972 acc 0.291\n",
            "  saving network\n",
            "epoch 077 : train loss 2.516 acc 0.373 test loss 2.971 acc 0.292\n",
            "  saving network\n",
            "epoch 078 : train loss 2.513 acc 0.373 test loss 2.971 acc 0.291\n",
            "  saving network\n",
            "epoch 079 : train loss 2.509 acc 0.374 test loss 2.971 acc 0.291\n",
            "  saving network\n",
            "epoch 080 : train loss 2.506 acc 0.375 test loss 2.970 acc 0.292\n",
            "  saving network\n",
            "epoch 081 : train loss 2.503 acc 0.376 test loss 2.970 acc 0.292\n",
            "  saving network\n",
            "epoch 082 : train loss 2.500 acc 0.376 test loss 2.970 acc 0.293\n",
            "  saving network\n",
            "epoch 083 : train loss 2.497 acc 0.377 test loss 2.970 acc 0.292\n",
            "  saving network\n",
            "epoch 084 : train loss 2.494 acc 0.378 test loss 2.969 acc 0.293\n",
            "  saving network\n",
            "epoch 085 : train loss 2.491 acc 0.378 test loss 2.969 acc 0.293\n",
            "  saving network\n",
            "epoch 086 : train loss 2.488 acc 0.379 test loss 2.969 acc 0.293\n",
            "  saving network\n",
            "epoch 087 : train loss 2.485 acc 0.379 test loss 2.969 acc 0.293\n",
            "  saving network\n",
            "epoch 088 : train loss 2.482 acc 0.379 test loss 2.969 acc 0.293\n",
            "  saving network\n",
            "epoch 089 : train loss 2.480 acc 0.379 test loss 2.969 acc 0.293\n",
            "  saving network\n",
            "epoch 090 : train loss 2.477 acc 0.380 test loss 2.969 acc 0.293\n",
            "  saving network\n",
            "epoch 091 : train loss 2.474 acc 0.381 test loss 2.969 acc 0.294\n",
            "  saving network\n",
            "epoch 092 : train loss 2.472 acc 0.382 test loss 2.969 acc 0.293\n",
            "epoch 093 : train loss 2.469 acc 0.382 test loss 2.969 acc 0.293\n",
            "epoch 094 : train loss 2.467 acc 0.383 test loss 2.969 acc 0.294\n",
            "epoch 095 : train loss 2.465 acc 0.383 test loss 2.969 acc 0.294\n",
            "epoch 096 : train loss 2.462 acc 0.384 test loss 2.969 acc 0.294\n",
            "epoch 097 : train loss 2.460 acc 0.385 test loss 2.969 acc 0.294\n",
            "epoch 098 : train loss 2.458 acc 0.385 test loss 2.969 acc 0.294\n",
            "epoch 099 : train loss 2.455 acc 0.386 test loss 2.970 acc 0.294\n",
            "epoch 100 : train loss 2.453 acc 0.386 test loss 2.970 acc 0.294\n",
            "epoch 101 : train loss 2.451 acc 0.386 test loss 2.970 acc 0.294\n",
            "epoch 102 : train loss 2.449 acc 0.387 test loss 2.970 acc 0.294\n",
            "epoch 103 : train loss 2.447 acc 0.387 test loss 2.970 acc 0.294\n",
            "epoch 104 : train loss 2.445 acc 0.388 test loss 2.970 acc 0.294\n",
            "epoch 105 : train loss 2.443 acc 0.388 test loss 2.971 acc 0.295\n",
            "epoch 106 : train loss 2.441 acc 0.389 test loss 2.971 acc 0.295\n",
            "epoch 107 : train loss 2.439 acc 0.390 test loss 2.971 acc 0.295\n",
            "epoch 108 : train loss 2.437 acc 0.390 test loss 2.971 acc 0.295\n",
            "epoch 109 : train loss 2.436 acc 0.391 test loss 2.972 acc 0.295\n",
            "epoch 110 : train loss 2.434 acc 0.391 test loss 2.972 acc 0.294\n",
            "epoch 111 : train loss 2.432 acc 0.391 test loss 2.972 acc 0.295\n",
            "done training.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ff85df784d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHOvGikERcUC"
      },
      "source": [
        "Draw the loss for training and the loss for testing. Do you see the\n",
        "training loss keep going down and the testing loss at some point\n",
        "rising above the testing curve?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxhdmM7vRcUC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ws9cV1HRcUC"
      },
      "source": [
        "Rewrite the training loop, and instead of running over the whole\n",
        "dataset, only run the first 5 minibatches. Run many more epochs. Redraw the curves\n",
        "for training and testing loss. You should find that the training loss tends to 0, while the testing loss shows the nice convex pattern shown in the lecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEpmtpn_RcUC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX9kHlu-RcUC"
      },
      "source": [
        "One final challenge. Create a large network (at least a million parameters). Run training for a couple hundred epochs, and check the testing and training losses. \n",
        "\n",
        "An aside, you may find the double descent curve, where the testing loss starts off going down, goes up as expected from bias-variance, but then starts to go down again. Why this happens is still unknown, but it is commonly seen training neural networks and possibly related to the mysterious generalizability of these networks with millions of parameters. \n",
        "\n",
        "https://openai.com/blog/deep-double-descent/\n",
        "\n",
        "(Note: this exact phenomena may be difficult to acheive without BatchNorm, which we will cover later, but try to train a large network to good accuracy for CIFAR100)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBM24GfQRcUC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSWycF88RcUD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}